{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a912a-76f3-4db5-9200-34175ef46a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7034f7-0808-4d70-b235-b62a480dfe1d",
   "metadata": {},
   "source": [
    "# Chinese BabyAGI\n",
    "\n",
    "> Using BabyAGI in Chinese to search the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87ce54-79b9-4e10-8e26-258ba2eda2e8",
   "metadata": {},
   "source": [
    "---\n",
    "* [BabyAGI with LangChain and Faiss](https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html)\n",
    "* [BabyAGI - LangChain Module](https://python.langchain.com/en/latest/use_cases/autonomous_agents/baby_agi.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c10eef-65ee-415d-ba90-1ffac82ada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import time\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97cdf1-ba06-45b7-94ea-6f77529e0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0ca1b-38d8-443d-a170-6d5baa63b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# define your embedding model\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name='GanymedeNil/text2vec-large-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca46a58-a76d-4b96-a2dc-72e090e90d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import faiss\n",
    "\n",
    "embedding_size = 1024\n",
    "# initialize the vectorstore as empty\n",
    "index = faiss.IndexFlatL2(embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14334512-61ad-43c4-a574-9bf44bbcbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20661d40-b701-46e6-a492-4b1c1474a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe5054-36ee-4e4e-ade8-63bf3b4736fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "class TaskCreationChain(LLMChain):\n",
    "    '''Chain to generates tasks.'''\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        '''Get the response parser.'''\n",
    "        task_creation_template = (\n",
    "            '你是一个创建任务的 AI，根据任务的执行结果创建新任务。\\n'\n",
    "            '* 我们的最终目标是「{objective}」\\n'\n",
    "            '* 上一次完成的任务是「{task_description}」\\n'\n",
    "            '  该任务的执行结果为：「\\n'\n",
    "            '{result}\\n'\n",
    "            '」\\n'\n",
    "            '* 这些是未完成的任务：「\\n'\n",
    "            '{incomplete_tasks}\\n'\n",
    "            '」\\n\\n'\n",
    "            '请根据上一次完成的任务的结果创建将由 AI 系统完成的新任务。\\n'\n",
    "            '* 请不要创建与未完成的任务重叠的新任务。\\n'\n",
    "            '* 请以带编号的清单形式回复结果，每行只描述一个新任务。\\n'\n",
    "            '  例如：\\n'\n",
    "            '  1. 第一个新任务\\n'\n",
    "            '  2. 第二个新任务\\n'\n",
    "            '* 请从编号 1 开始列出新任务清单。'\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_creation_template,\n",
    "            input_variables=[\n",
    "                'objective',\n",
    "                'task_description',\n",
    "                'result',\n",
    "                'incomplete_tasks',\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc15e95-df62-4231-bacf-c0f044abe0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "class TaskPrioritizationChain(LLMChain):\n",
    "    '''Chain to prioritize tasks.'''\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        '''Get the response parser.'''\n",
    "        task_prioritization_template = (\n",
    "            '你是一个根据任务与「最终目标」的相似度给任务的优先级进行排序的 AI。\\n'\n",
    "            '* 我们的最终目标是「{objective}」\\n\\n'\n",
    "            '请清理并根据与「最终目标」的相似度从高到低重新排序以下任务：{task_names}。\\n'\n",
    "            '* 请以带编号的清单形式回复结果，每行只描述一个任务。\\n'\n",
    "            '  例如：\\n'\n",
    "            '  {next_task_id}. 第一个任务\\n'\n",
    "            '  {next_next_task_id}. 第二个任务\\n'\n",
    "            '* 请从编号 {next_task_id} 开始列出任务清单。'\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template=task_prioritization_template,\n",
    "            input_variables=[\n",
    "                'objective',\n",
    "                'task_names',\n",
    "                'next_task_id',\n",
    "                'next_next_task_id',\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc7c14-df3e-453b-b377-2f03e2f1b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "class ExecutionChain(LLMChain):\n",
    "    '''Chain to execute tasks.'''\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
    "        '''Get the response parser.'''\n",
    "        execution_template = (\n",
    "            '你是一个执行任务的 AI。\\n'\n",
    "            '* 我们的最终目标是「{objective}」\\n'\n",
    "            '* 之前已经完成的任务有：{context}\\n\\n'\n",
    "            '请完成这次任务：「{task}」。\\n'\n",
    "            '* 直接回复这次任务的执行结果。'\n",
    "        )\n",
    "        prompt = PromptTemplate(\n",
    "            template = execution_template,\n",
    "            input_variables = [\n",
    "                'objective',\n",
    "                'context',\n",
    "                'task',\n",
    "            ],\n",
    "        )\n",
    "        return cls(prompt = prompt, llm = llm, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5526f5f-1d72-400c-8960-275a918326a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "def get_next_task(\n",
    "    task_creation_chain: LLMChain,\n",
    "    result: Dict,\n",
    "    task_description: str,\n",
    "    task_list: List[str],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    '''Get the next task.'''\n",
    "    incomplete_tasks = '\\n'.join(task_list)\n",
    "    response = task_creation_chain.run(\n",
    "        objective = objective,\n",
    "        task_description = task_description,\n",
    "        result = result,\n",
    "        incomplete_tasks = incomplete_tasks,\n",
    "    )\n",
    "    new_tasks = response.split('\\n')\n",
    "    new_tasks = [task_name.split('.', 1) for task_name in new_tasks]\n",
    "    new_tasks = [task_name[1].strip() for task_name in new_tasks if len(task_name)==2]\n",
    "    return [{'task_name': task_name} for task_name in new_tasks if task_name.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d554c24-9e29-436a-93ab-fd659606f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "def prioritize_tasks(\n",
    "    task_prioritization_chain: LLMChain,\n",
    "    this_task_id: int,\n",
    "    task_list: List[Dict],\n",
    "    objective: str,\n",
    ") -> List[Dict]:\n",
    "    '''Prioritize tasks.'''\n",
    "    task_names = [t['task_name'] for t in task_list]\n",
    "    next_task_id = int(this_task_id) + 1\n",
    "    response = task_prioritization_chain.run(\n",
    "        objective = objective, task_names = task_names, next_task_id = next_task_id, next_next_task_id = next_task_id + 1,\n",
    "    )\n",
    "    new_tasks = response.split('\\n')\n",
    "    prioritized_task_list = []\n",
    "    for task_string in new_tasks:\n",
    "        if not task_string.strip():\n",
    "            continue\n",
    "        task_parts = task_string.strip().split('.', 1)\n",
    "        if len(task_parts) == 2:\n",
    "            # task_id = task_parts[0].strip()\n",
    "            task_name = task_parts[1].strip()\n",
    "            prioritized_task_list.append({'task_id': next_task_id, 'task_name': task_name})\n",
    "            next_task_id += 1\n",
    "    return prioritized_task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa601b-b979-4233-bfd3-7313f70563a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "def get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n",
    "    '''Get the top k tasks based on the query.'''\n",
    "    results = vectorstore.similarity_search_with_score(query, k = k)\n",
    "    if not results:\n",
    "        return []\n",
    "    sorted_results, _ = zip(*sorted(results, key = lambda x: x[1], reverse = True))\n",
    "    return [str(item.metadata['task']) for item in sorted_results]\n",
    "\n",
    "\n",
    "def execute_task(\n",
    "    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n",
    ") -> str:\n",
    "    '''Execute a task.'''\n",
    "    context = get_top_tasks(vectorstore, query = objective, k = k)\n",
    "    return execution_chain.run(objective = objective, context = context, task = task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598af62-1381-4159-b886-504649a9ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BabyAGI(Chain, BaseModel):\n",
    "    '''Controller model for the BabyAGI agent.'''\n",
    "\n",
    "    task_list: deque = Field(default_factory=deque)\n",
    "    task_creation_chain: TaskCreationChain = Field(...)\n",
    "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
    "    execution_chain: Chain = Field(...)\n",
    "    task_id_counter: int = Field(1)\n",
    "    vectorstore: VectorStore = Field(init=False)\n",
    "    max_iterations: Optional[int] = None\n",
    "\n",
    "    class Config:\n",
    "        '''Configuration for this pydantic object.'''\n",
    "\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def add_task(self, task: Dict):\n",
    "        self.task_list.append(task)\n",
    "\n",
    "    def print_task_list(self):\n",
    "        print('\\033[95m\\033[1m' + '\\n*****TASK LIST*****\\n' + '\\033[0m\\033[0m')\n",
    "        for t in self.task_list:\n",
    "            print(str(t['task_id']) + ': ' + t['task_name'])\n",
    "\n",
    "    def print_next_task(self, task: Dict):\n",
    "        print('\\033[92m\\033[1m' + '\\n*****NEXT TASK*****\\n' + '\\033[0m\\033[0m')\n",
    "        print(str(task['task_id']) + ': ' + task['task_name'])\n",
    "\n",
    "    def print_task_result(self, result: str):\n",
    "        print('\\033[93m\\033[1m' + '\\n*****TASK RESULT*****\\n' + '\\033[0m\\033[0m')\n",
    "        print(result)\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        return ['objective']\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return []\n",
    "\n",
    "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        '''Run the agent.'''\n",
    "        objective = inputs['objective']\n",
    "        first_task = inputs.get('first_task', f'制作一个最终目标「{objective}」的待办事项清单。')\n",
    "        num_iters = 0\n",
    "        while True:\n",
    "            if self.task_list == deque():\n",
    "                self.task_id_counter += 1\n",
    "                self.add_task({'task_id': self.task_id_counter, 'task_name': first_task})\n",
    "\n",
    "            self.print_task_list()\n",
    "\n",
    "            # Step 1: Pull the first task\n",
    "            task = self.task_list.popleft()\n",
    "            self.print_next_task(task)\n",
    "\n",
    "            # Step 2: Execute the task\n",
    "            # todo: while result == ''\n",
    "            result = execute_task(\n",
    "                self.vectorstore, self.execution_chain, objective, task['task_name']\n",
    "            )\n",
    "            time.sleep(0)\n",
    "            this_task_id = int(task['task_id'])\n",
    "            self.print_task_result(result)\n",
    "\n",
    "            # Step 3: Store the result in Faiss\n",
    "            result_id = f'result_{task[\"task_id\"]}'\n",
    "            self.vectorstore.add_texts(\n",
    "                texts = [result],\n",
    "                metadatas = [{'task': task['task_name']}],\n",
    "                ids = [result_id],\n",
    "            )\n",
    "\n",
    "            # Step 4: Create new tasks and reprioritize task list\n",
    "            new_tasks = get_next_task(\n",
    "                self.task_creation_chain,\n",
    "                result,\n",
    "                task['task_name'],\n",
    "                [t['task_name'] for t in self.task_list],\n",
    "                objective,\n",
    "            )\n",
    "            time.sleep(0)\n",
    "            for new_task in new_tasks:\n",
    "                self.task_id_counter += 1\n",
    "                new_task.update({'task_id': self.task_id_counter})\n",
    "                self.add_task(new_task)\n",
    "            self.task_list = deque(\n",
    "                prioritize_tasks(\n",
    "                    self.task_prioritization_chain,\n",
    "                    this_task_id,\n",
    "                    list(self.task_list),\n",
    "                    objective,\n",
    "                )\n",
    "            )\n",
    "            time.sleep(0)\n",
    "\n",
    "            num_iters += 1\n",
    "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
    "                print(\n",
    "                    '\\033[91m\\033[1m' + '\\n*****TASK ENDING*****\\n' + '\\033[0m\\033[0m'\n",
    "                )\n",
    "                break\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls, llm: BaseLLM, vectorstore: VectorStore,\n",
    "        task_execution_chain: Optional[Chain] = None,\n",
    "        verbose: bool = False, **kwargs\n",
    "    ) -> 'BabyAGI':\n",
    "        '''Initialize the BabyAGI Controller.'''\n",
    "        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n",
    "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
    "            llm, verbose=verbose\n",
    "        )\n",
    "        if task_execution_chain is None:\n",
    "            execution_chain = ExecutionChain.from_llm(llm, verbose=verbose)\n",
    "        else:\n",
    "            execution_chain = task_execution_chain\n",
    "        return cls(\n",
    "            task_creation_chain = task_creation_chain,\n",
    "            task_prioritization_chain = task_prioritization_chain,\n",
    "            execution_chain = execution_chain,\n",
    "            vectorstore = vectorstore,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a8fce-2f01-49d3-ab0c-99715435e826",
   "metadata": {},
   "source": [
    "---\n",
    "With Tools\n",
    "* [BabyAGI with Tools - LangChain Module](https://python.langchain.com/en/latest/use_cases/autonomous_agents/baby_agi_with_agent.html)\n",
    "* [LangChain Utilities](https://github.com/hwchase17/langchain/tree/master/langchain/utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd2fda-d8d9-4250-aeb0-c7c8bca51a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.agents import Tool\n",
    "from ipymock.reader import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = '搜索',\n",
    "        func = DuckDuckGoSearchAPIWrapper().run,\n",
    "        description = (\n",
    "            '如果你需要在互联网上搜索一些你所不确定的最新信息来回答相关问题，请回复：「\\n'\n",
    "            '行动：搜索\\n'\n",
    "            '行动输入：你需要搜索的主题\\n'\n",
    "            '」\\n'\n",
    "            '我将替你在互联网上搜索并给出搜索结果。\\n'\n",
    "            '注意：你的回复中不能包含「行动输出」的字眼，也不能包含「最终结果」的字眼；否则，我会认为你已经确定了「行动输出」或者「最终结果」、也就是已经确定了具体的搜索结果，我就不会再给你提供相应的搜索结果了。'\n",
    "        ),\n",
    "        return_direct = True,\n",
    "    ),\n",
    "    # Tool(\n",
    "    #     name = '待办事项',\n",
    "    #     func = LLMChain(\n",
    "    #         llm = OpenAI(temperature = 0, verbose = False),\n",
    "    #         prompt = PromptTemplate.from_template(\n",
    "    #             '你是一个计划师，擅长为特定目标制定待办清单。\\n为以下目标制定一个待办清单：「\\n{objective}\\n」。'\n",
    "    #         )\n",
    "    #     ).run,\n",
    "    #     description = '适用于需要创建待办事项清单的情况。动作输入：需要创建待办事项清单的最终目标。动作输出：该目标的待办事项清单。请明确指定目标！',\n",
    "    #     return_direct = True,\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727b3a9-6a33-4086-ae57-fd57dd9ab59f",
   "metadata": {},
   "source": [
    "---\n",
    "Executor\n",
    "* [LangChain ZeroShotAgent](https://sj-langchain.readthedocs.io/en/latest/modules/agents/examples/custom_agent.html)\n",
    "  * [Source Code](https://github.com/hwchase17/langchain/blob/master/langchain/agents/mrkl/base.py)\n",
    "  * [Modular Reasoning, Knowledge and Language system](https://arxiv.org/pdf/2205.00445.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76a426-ce77-48dd-8f79-7c21654602c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "from langchain.agents import AgentExecutor, ZeroShotAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bbcff-5077-4302-a252-97a134a8dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ZeroRoundAgent(ZeroShotAgent):\n",
    "    @property\n",
    "    def observation_prefix(self) -> str:\n",
    "        '''Prefix to append the observation with.'''\n",
    "        return '行动输出：'\n",
    "\n",
    "    @property\n",
    "    def llm_prefix(self) -> str:\n",
    "        '''Prefix to append the llm call with.'''\n",
    "        return '思考：'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c0eb8f-0b91-4fef-84d6-0eb74398650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from langchain import OpenAI\n",
    "llm = OpenAI(temperature = 0, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b904311-dc63-4e1d-a7ea-03dc312753a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "FORMAT_INSTRUCTIONS = '''使用以下格式进行回复：「\n",
    "任务：你这次必须完成的任务\n",
    "\n",
    "思考：这次任务和我们的「最终目标」有什么关系？怎么完成这次任务以朝着我们的「最终目标」前进？\n",
    "行动：这是你所需要采取的行动。请选择 [{tool_names}, ] 中的一个行动。\n",
    "行动输入：这是与行动相关的输入。\n",
    "行动输出：\n",
    "这是行动所导致的输出。\n",
    "请**避免**编造虚假的「行动输出」。\n",
    "如果你不确定「行动输出」并且需要我回复与具体的「行动输出」相关的信息来帮助你完成任务，请避免在你的回复中包含「行动输出」的字眼。\n",
    "如果你的回复中包含「行动输出」的字眼，那么我会认为你已经确定了「行动输出」，我就不会给你提供相应的帮助了。\n",
    "\n",
    "思考：我现在得到了最终结果／我还不能完全确定最终结果\n",
    "最终结果：\n",
    "如果你可以确定已经得到了这次任务的最终的具体结果，请详尽地报告「最终结果」。\n",
    "请**避免**编造虚假的「最终结果」。如果你不确定「最终结果」，请避免在你的回复中包含「最终结果」的字眼。如果你的回复中包含「最终结果」的字眼，那么我会认为你已经确确实实地完成了这次任务，也就不会和你再交流这次任务。\n",
    "」'''\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = ZeroRoundAgent.create_prompt(\n",
    "        tools,\n",
    "        prefix = '''你是一个执行任务的 AI。\\n我们的最终目标是「{objective}」。\\n已完成的任务有：{context}。''',\n",
    "        suffix = '''请完成这次任务：「{task}」\\n\\n完成这次任务的步骤如下：「\\n{agent_scratchpad}''',\n",
    "        format_instructions = FORMAT_INSTRUCTIONS,\n",
    "        input_variables = ['objective', 'task', 'context', 'agent_scratchpad'],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e73bd7-d080-4535-a8c4-fd825dbdf498",
   "metadata": {},
   "source": [
    "[LangChain MRKLOutputParser](https://github.com/hwchase17/langchain/blob/master/langchain/agents/mrkl/output_parser.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76401b1-853e-4aab-b95c-0175836d2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re\n",
    "from typing import Union\n",
    "\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "\n",
    "FINAL_ANSWER_ACTION = r'最终结果\\s*[：|:]\\s*(.*)'\n",
    "\n",
    "\n",
    "class ChineseOutputParser(AgentOutputParser):\n",
    "\n",
    "    default_action: Optional[str] = None\n",
    "    default_action_input: Optional[str] = None\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return FORMAT_INSTRUCTIONS\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        match = re.search(FINAL_ANSWER_ACTION, text, re.DOTALL)\n",
    "        if match:\n",
    "            return AgentFinish({'output': match.group(1).strip()}, text)\n",
    "        # \\s matches against tab/newline/whitespace\n",
    "        regex = r'\\s*行动\\s*\\d*\\s*[：|:]\\s*([^\\s]+)\\s*行动输入\\s*\\d*\\s*[：|:]\\s*([^\\n]+)\\n*'\n",
    "        matches = re.findall(regex, text)\n",
    "        if not matches:\n",
    "            if self.default_action is not None and self.default_action_input is not None:\n",
    "                return AgentAction(self.default_action, self.default_action_input, text)\n",
    "            else:\n",
    "                return AgentFinish({'output': ''}, text)\n",
    "            raise OutputParserException(f'Could not parse LLM output: `{text}`')\n",
    "        action_list = []\n",
    "        for match in matches[:1]:\n",
    "            action = match[0].strip()\n",
    "            if '搜索' in action:\n",
    "                action = '搜索'\n",
    "            else:\n",
    "                continue\n",
    "            action_input = match[1].strip(' ').strip('\"')\n",
    "            action_list.append(AgentAction(action, action_input, text))\n",
    "        if action_list == []:\n",
    "            return AgentFinish({'output': ''}, text)\n",
    "        return action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2a259-4d55-47df-9253-4ebe0037da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent = ZeroRoundAgent(\n",
    "        llm_chain = llm_chain, allowed_tools = [tool.name for tool in tools], output_parser = ChineseOutputParser()\n",
    "    ),\n",
    "    tools = tools, verbose = True, max_iterations = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f5adfd-c2b3-443a-bf2b-e17340923622",
   "metadata": {},
   "source": [
    "---\n",
    "Running the BabyAGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023ff81-12bd-4237-bdf9-2eec2c8d1e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# verbose: logging of LLMChains\n",
    "# max_iterations: Optional[int]\n",
    "# if None, agi will keep on going forever\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm = llm, vectorstore = vectorstore, task_execution_chain = agent_executor, verbose = True, max_iterations = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43661afd-6a0f-477a-8930-cc8d631070f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "final_objective = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e249925-f372-4060-9b24-e33c7098f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "def test_baby_agi(mock_openai):\n",
    "    baby_agi({'objective': final_objective})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371acce-7e24-49b2-b056-596703adbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import ipymock\n",
    "import ipymock.browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdedd3-eb6e-4569-9284-699a91c43990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "common = ipymock.browser.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e66b98-d951-4904-aa79-ecd64735e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mock_baby_agi(objective):\n",
    "    global final_objective\n",
    "    final_objective = objective\n",
    "    ipymock.do(\n",
    "        mock_openai = ipymock.browser.mock_openai,\n",
    "        test_baby_agi = test_baby_agi,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
